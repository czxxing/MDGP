"""
æ•°æ®å¤„ç†é¡µé¢æ¨¡å— - ä½¿ç”¨mdgp_processorsè¿›è¡Œæ•°æ®å¤„ç†å·¥ä½œæµæ„å»º
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, List, Optional
import logging
import matplotlib.pyplot as plt
from datetime import datetime
import daft
import json
import uuid
import base64
from io import BytesIO

# å¯¼å…¥mdgp_processors
from mdgp_processors import Operator, DataPipeline
from mdgp_processors.ops import (
    # Readers
    CSVReader, LanceReader, JSONReader, ParquetReader,
    ImageReader, AudioReader,
    # Writers
    CSVWriter, LanceWriter,
    # Filters
    TextLengthFilter, ImageResolutionFilter, AudioDurationFilter,
    QualityScoreFilter,
    # Dedupers
    TextDeduper,
    # Evaluators
    TextQualityEvaluator
)

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class DataProcessingPage:
    """æ•°æ®å¤„ç†é¡µé¢ç±» - ä½¿ç”¨mdgp_processorsæ„å»ºå·¥ä½œæµ"""
    
    def __init__(self, lance_manager):
        self.lance_manager = lance_manager
        self.logger = self._setup_logging()
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'current_dataframe' not in st.session_state:
            st.session_state.current_dataframe = None
        if 'workflow_operators' not in st.session_state:
            st.session_state.workflow_operators = []
        if 'workflow_results' not in st.session_state:
            st.session_state.workflow_results = None
        if 'processing_logs' not in st.session_state:
            st.session_state.processing_logs = []
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = {}
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def get_title(self):
        """è·å–é¡µé¢æ ‡é¢˜"""
        return "æ•°æ®å¤„ç†"
    
    def get_description(self):
        """è·å–é¡µé¢æè¿°"""
        return "ä½¿ç”¨mdgp_processorsæ„å»ºæ•°æ®å¤„ç†å·¥ä½œæµ"
    
    def display(self):
        """æ˜¾ç¤ºæ•°æ®å¤„ç†å†…å®¹"""
        st.header("ğŸ“Š æ•°æ®å¤„ç†å·¥ä½œæµæ„å»º")
        
        # åˆ›å»ºé¡µé¢å¸ƒå±€
        self._setup_page_layout()
        
    def _setup_page_layout(self):
        """è®¾ç½®é¡µé¢å¸ƒå±€"""
        # ä½¿ç”¨æ ‡ç­¾é¡µç»„ç»‡å†…å®¹
        tab1, tab2, tab3 = st.tabs(["å·¥ä½œæµæ„å»º", "æ•°æ®åŠ è½½", "ç»“æœå±•ç¤º"])
        
        with tab1:
            self._display_workflow_builder()
        
        with tab2:
            self._display_data_loading_section()
        
        with tab3:
            self._display_results_section()
    
    def _display_data_loading_section(self):
        """æ˜¾ç¤ºæ•°æ®åŠ è½½åŒºåŸŸ"""
        st.subheader("ğŸ“¥ æ•°æ®åŠ è½½")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ä»æ•°æ®åº“åŠ è½½æ•°æ®", use_container_width=True):
                with st.spinner("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½æ•°æ®..."):
                    df = self.lance_manager.load_from_lance()
                    if df is not None and not df.empty:
                        st.session_state.current_dataframe = df
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
                        self._add_log("æ•°æ®åŠ è½½", f"æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
                    else:
                        st.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¯·å…ˆåœ¨æ•°æ®ç›®å½•é¡µé¢å¯¼å…¥æ•°æ®")
        
        with col2:
            if st.session_state.current_dataframe is not None:
                st.metric("å½“å‰æ•°æ®é‡", len(st.session_state.current_dataframe))
            else:
                st.info("ğŸ“Š ç­‰å¾…æ•°æ®åŠ è½½")
        
        with col3:
            if st.session_state.current_dataframe is not None:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®", use_container_width=True):
                    st.session_state.current_dataframe = None
                    st.session_state.workflow_results = None
                    st.session_state.processing_logs = []
                    st.session_state.analysis_results = {}
                    st.rerun()
        
        # æ•°æ®é¢„è§ˆ
        if st.session_state.current_dataframe is not None:
            self._display_data_preview()
    
    def _display_data_preview(self):
        """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
        st.subheader("ğŸ‘€ æ•°æ®é¢„è§ˆ")
        
        df = st.session_state.current_dataframe
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è®°å½•æ•°", len(df))
        with col2:
            st.metric("åˆ—æ•°", len(df.columns))
        with col3:
            st.metric("æ•°æ®ç±»å‹", f"{len(df.select_dtypes(include=['object']).columns)}æ–‡æœ¬åˆ—")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…"):
            st.dataframe(df.head(10), use_container_width=True)
            
            # æ˜¾ç¤ºåˆ—ä¿¡æ¯
            st.write("**åˆ—ä¿¡æ¯:**")
            col_info = pd.DataFrame({
                'åˆ—å': df.columns,
                'æ•°æ®ç±»å‹': [str(dtype) for dtype in df.dtypes.values],
                'éç©ºå€¼æ•°': df.count().values,
                'ç¼ºå¤±å€¼æ•°': df.isnull().sum().values
            })
            st.dataframe(col_info, use_container_width=True)
    
    def _display_workflow_builder(self):
        """æ˜¾ç¤ºå·¥ä½œæµæ„å»ºåŒºåŸŸ"""
        st.subheader("ğŸ”§ å·¥ä½œæµæ„å»º")
        
        # ç®—å­åº“å’Œå·¥ä½œæµåŒºåŸŸ
        col1, col2 = st.columns([1, 3], gap="medium")
        
        with col1:
            st.subheader("ğŸ§© ç®—å­åº“")
            self._display_operator_library()
        
        with col2:
            st.subheader("ğŸ“‹ å·¥ä½œæµ")
            self._display_workflow_canvas()
    
    def _display_operator_library(self):
        """æ˜¾ç¤ºç®—å­åº“"""
        # ç®—å­åˆ†ç±»
        operator_categories = {
            "è¯»å–å™¨": [CSVReader, LanceReader, JSONReader, ParquetReader, ImageReader, AudioReader],
            "è¿‡æ»¤å™¨": [TextLengthFilter, ImageResolutionFilter, AudioDurationFilter, QualityScoreFilter],
            "è¯„ä¼°å™¨": [TextQualityEvaluator],
            "å»é‡å™¨": [TextDeduper],
            "å†™å…¥å™¨": [CSVWriter, LanceWriter]
        }
        
        for category, operators in operator_categories.items():
            with st.expander(f"{category}"):
                for operator_class in operators:
                    if st.button(
                        f"â• {operator_class.__name__}",
                        use_container_width=True,
                        key=f"add_{operator_class.__name__}"
                    ):
                        self._add_operator_to_workflow(operator_class)
    
    def _add_operator_to_workflow(self, operator_class):
        """æ·»åŠ ç®—å­åˆ°å·¥ä½œæµ"""
        # åˆ›å»ºç®—å­å®ä¾‹
        operator_id = str(uuid.uuid4())
        operator = operator_class()
        
        # ä¿å­˜ç®—å­ä¿¡æ¯
        operator_info = {
            "id": operator_id,
            "class_name": operator_class.__name__,
            "instance": operator,
            "params": self._get_operator_params(operator_class),
            "position": {"x": 100, "y": 100}
        }
        
        # æ·»åŠ åˆ°å·¥ä½œæµ
        st.session_state.workflow_operators.append(operator_info)
        
        self._add_log("å·¥ä½œæµæ„å»º", f"æ·»åŠ ç®—å­: {operator_class.__name__}")
    
    def _get_operator_params(self, operator_class):
        """è·å–ç®—å­å‚æ•°ä¿¡æ¯"""
        # è¿™é‡Œå¯ä»¥é€šè¿‡åå°„è·å–ç®—å­çš„å‚æ•°ä¿¡æ¯
        # ç®€å•å®ç°ï¼Œæ ¹æ®ä¸åŒç®—å­è¿”å›é»˜è®¤å‚æ•°
        params = {}
        
        if operator_class == TextLengthFilter:
            params = {
                "text_column": "text",
                "min_length": 0,
                "max_length": None
            }
        elif operator_class == TextQualityEvaluator:
            params = {
                "text_column": "text",
                "score_column": "text_quality_score"
            }
        elif operator_class == CSVReader:
            params = {
                "file_path": "",
                "delimiter": ","
            }
        elif operator_class == CSVWriter:
            params = {
                "file_path": "",
                "delimiter": ","
            }
        elif operator_class == QualityScoreFilter:
            params = {
                "score_column": "text_quality_score",
                "threshold": 0.5
            }
        
        return params
    
    def _display_workflow_canvas(self):
        """æ˜¾ç¤ºå·¥ä½œæµç”»å¸ƒ"""
        # å·¥ä½œæµç”»å¸ƒ
        workflow_container = st.container(height=500)
        
        with workflow_container:
            # æ˜¾ç¤ºå·¥ä½œæµä¸­çš„ç®—å­
            if st.session_state.workflow_operators:
                for i, operator_info in enumerate(st.session_state.workflow_operators):
                    self._display_operator_card(i, operator_info)
                
                # æ·»åŠ è¿è¡ŒæŒ‰é’®
                if st.button("ğŸš€ è¿è¡Œå·¥ä½œæµ", use_container_width=True):
                    self._run_workflow()
                
                # æ·»åŠ æ¸…é™¤æŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…é™¤å·¥ä½œæµ", use_container_width=True):
                    st.session_state.workflow_operators = []
                    st.rerun()
            else:
                st.info("ğŸ“‹ ä»å·¦ä¾§ç®—å­åº“æ‹–æ‹½ç®—å­åˆ°æ­¤å¤„æ„å»ºå·¥ä½œæµ")
    
    def _display_operator_card(self, index: int, operator_info: Dict[str, Any]):
        """æ˜¾ç¤ºç®—å­å¡ç‰‡"""
        operator = operator_info["instance"]
        params = operator_info["params"]
        
        with st.expander(f"{index+1}. {operator.name}", expanded=True):
            # æ˜¾ç¤ºç®—å­å‚æ•°é…ç½®
            self._display_operator_params(operator, params)
            
            # æ·»åŠ åˆ é™¤æŒ‰é’®
            if st.button(f"âŒ åˆ é™¤", key=f"delete_{operator_info['id']}"):
                st.session_state.workflow_operators.pop(index)
                st.rerun()
    
    def _display_operator_params(self, operator: Operator, params: Dict[str, Any]):
        """æ˜¾ç¤ºç®—å­å‚æ•°é…ç½®"""
        # æ ¹æ®ç®—å­ç±»å‹æ˜¾ç¤ºä¸åŒçš„å‚æ•°é…ç½®
        if isinstance(operator, TextLengthFilter):
            params["text_column"] = st.text_input("æ–‡æœ¬åˆ—å", value=params["text_column"])
            params["min_length"] = st.number_input("æœ€å°é•¿åº¦", min_value=0, value=params["min_length"])
            params["max_length"] = st.number_input("æœ€å¤§é•¿åº¦", min_value=0, value=params["max_length"] or 1000, step=1)
        
        elif isinstance(operator, TextQualityEvaluator):
            params["text_column"] = st.text_input("æ–‡æœ¬åˆ—å", value=params["text_column"])
            params["score_column"] = st.text_input("åˆ†æ•°åˆ—å", value=params["score_column"])
        
        elif isinstance(operator, QualityScoreFilter):
            params["score_column"] = st.text_input("åˆ†æ•°åˆ—å", value=params["score_column"])
            params["threshold"] = st.slider("è´¨é‡é˜ˆå€¼", min_value=0.0, max_value=1.0, value=params["threshold"])
        
        elif isinstance(operator, CSVReader):
            params["file_path"] = st.text_input("æ–‡ä»¶è·¯å¾„", value=params["file_path"])
            params["delimiter"] = st.text_input("åˆ†éš”ç¬¦", value=params["delimiter"])
        
        elif isinstance(operator, CSVWriter):
            params["file_path"] = st.text_input("æ–‡ä»¶è·¯å¾„", value=params["file_path"])
            params["delimiter"] = st.text_input("åˆ†éš”ç¬¦", value=params["delimiter"])
    
    def _run_workflow(self):
        """è¿è¡Œå·¥ä½œæµ"""
        if not st.session_state.workflow_operators:
            st.error("âŒ å·¥ä½œæµä¸ºç©ºï¼Œè¯·æ·»åŠ ç®—å­")
            return
        
        if st.session_state.current_dataframe is None:
            st.error("âŒ æ²¡æœ‰åŠ è½½æ•°æ®ï¼Œè¯·å…ˆåŠ è½½æ•°æ®")
            return
        
        with st.spinner("æ­£åœ¨è¿è¡Œå·¥ä½œæµ..."):
            try:
                # è½¬æ¢æ•°æ®æ ¼å¼
                df = st.session_state.current_dataframe
                
                # åˆå§‹åŒ–ç®¡é“
                pipeline = DataPipeline()
                pipeline.set_input(df)
                
                # æ·»åŠ ç®—å­åˆ°ç®¡é“
                for operator_info in st.session_state.workflow_operators:
                    operator = operator_info["instance"]
                    params = operator_info["params"]
                    
                    # æ›´æ–°ç®—å­å‚æ•°
                    self._update_operator_params(operator, params)
                    
                    pipeline.add_operator(operator)
                
                # è¿è¡Œç®¡é“
                result_df = pipeline.run()
                
                # ä¿å­˜ç»“æœ
                st.session_state.workflow_results = result_df
                st.success(f"âœ… å·¥ä½œæµè¿è¡Œå®Œæˆï¼ç»“æœåŒ…å« {len(result_df)} æ¡è®°å½•")
                
                self._add_log("å·¥ä½œæµè¿è¡Œ", f"å·¥ä½œæµè¿è¡Œå®Œæˆï¼Œç»“æœåŒ…å« {len(result_df)} æ¡è®°å½•")
                
                # åˆ†æç»“æœ
                self._analyze_workflow_results(result_df)
                
            except Exception as e:
                st.error(f"âŒ å·¥ä½œæµè¿è¡Œå¤±è´¥: {str(e)}")
                self._add_log("å·¥ä½œæµè¿è¡Œ", f"è¿è¡Œå¤±è´¥: {str(e)}", "ERROR")
    
    def _update_operator_params(self, operator: Operator, params: Dict[str, Any]):
        """æ›´æ–°ç®—å­å‚æ•°"""
        for param_name, param_value in params.items():
            if hasattr(operator, param_name):
                setattr(operator, param_name, param_value)
    
    def _analyze_workflow_results(self, df: daft.DataFrame):
        """åˆ†æå·¥ä½œæµç»“æœ"""
        # åˆ†æç»“æœ
        results = {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è´¨é‡åˆ†æ•°åˆ—
        if "text_quality_score" in df.columns:
            # è®¡ç®—è´¨é‡åˆ†æ•°ç»Ÿè®¡
            score_stats = self._calculate_score_statistics(df)
            results["text_quality_score"] = score_stats
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬é•¿åº¦åˆ—
        if "text_length" in df.columns:
            # è®¡ç®—æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
            length_stats = self._calculate_length_statistics(df)
            results["text_length"] = length_stats
        
        st.session_state.analysis_results = results
    
    def _calculate_score_statistics(self, df: daft.DataFrame):
        """è®¡ç®—è´¨é‡åˆ†æ•°ç»Ÿè®¡"""
        # å°†daft DataFrameè½¬æ¢ä¸ºpandas DataFrame
        pd_df = df.to_pandas()
        
        scores = pd_df["text_quality_score"]
        
        return {
            "mean": scores.mean(),
            "median": scores.median(),
            "std": scores.std(),
            "min": scores.min(),
            "max": scores.max(),
            "count": len(scores),
            "pass_count": (scores >= 0.5).sum(),
            "pass_rate": (scores >= 0.5).sum() / len(scores)
        }
    
    def _calculate_length_statistics(self, df: daft.DataFrame):
        """è®¡ç®—æ–‡æœ¬é•¿åº¦ç»Ÿè®¡"""
        # å°†daft DataFrameè½¬æ¢ä¸ºpandas DataFrame
        pd_df = df.to_pandas()
        
        lengths = pd_df["text_length"]
        
        return {
            "mean": lengths.mean(),
            "median": lengths.median(),
            "std": lengths.std(),
            "min": lengths.min(),
            "max": lengths.max(),
            "count": len(lengths)
        }
    
    def _display_results_section(self):
        """æ˜¾ç¤ºç»“æœå±•ç¤ºåŒºåŸŸ"""
        st.subheader("ğŸ“ˆ ç»“æœå±•ç¤º")
        
        if st.session_state.workflow_results is None:
            st.info("ğŸ“‹ è¿è¡Œå·¥ä½œæµåæŸ¥çœ‹ç»“æœ")
            return
        
        # æ˜¾ç¤ºç»“æœé¢„è§ˆ
        self._display_results_preview()
        
        # æ˜¾ç¤ºåˆ†æå›¾è¡¨
        self._display_analysis_charts()
    
    def _display_results_preview(self):
        """æ˜¾ç¤ºç»“æœé¢„è§ˆ"""
        st.subheader("ğŸ‘€ ç»“æœé¢„è§ˆ")
        
        df = st.session_state.workflow_results
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è®°å½•æ•°", len(df))
        with col2:
            st.metric("åˆ—æ•°", len(df.columns))
        with col3:
            st.metric("å¤„ç†æ—¶é—´", "0.1s")  # å¯ä»¥ä»å·¥ä½œæµä¸­è·å–çœŸå®æ—¶é—´
        
        # æ˜¾ç¤ºæ•°æ®
        with st.expander("æŸ¥çœ‹ç»“æœæ•°æ®"):
            st.dataframe(df.head(10), use_container_width=True)
    
    def _display_analysis_charts(self):
        """æ˜¾ç¤ºåˆ†æå›¾è¡¨"""
        st.subheader("ğŸ“Š åˆ†æå›¾è¡¨")
        
        if not st.session_state.analysis_results:
            st.info("ğŸ“ˆ æ²¡æœ‰åˆ†æç»“æœ")
            return
        
        # æ ¹æ®åˆ†æç»“æœæ˜¾ç¤ºä¸åŒçš„å›¾è¡¨
        for analysis_type, results in st.session_state.analysis_results.items():
            if analysis_type == "text_quality_score":
                self._display_quality_score_chart(results)
            elif analysis_type == "text_length":
                self._display_text_length_chart(results)
    
    def _display_quality_score_chart(self, results: Dict[str, Any]):
        """æ˜¾ç¤ºè´¨é‡åˆ†æ•°å›¾è¡¨"""
        with st.expander("æ–‡æœ¬è´¨é‡åˆ†æ•°åˆ†æ", expanded=True):
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write("**ç»Ÿè®¡ä¿¡æ¯:**")
                stats_df = pd.DataFrame({
                    "æŒ‡æ ‡": ["å¹³å‡åˆ†", "ä¸­ä½æ•°", "æ ‡å‡†å·®", "æœ€å°å€¼", "æœ€å¤§å€¼", "é€šè¿‡æ•°é‡", "é€šè¿‡ç‡"],
                    "å€¼": [
                        f"{results['mean']:.2f}",
                        f"{results['median']:.2f}",
                        f"{results['std']:.2f}",
                        f"{results['min']:.2f}",
                        f"{results['max']:.2f}",
                        results['pass_count'],
                        f"{results['pass_rate']*100:.1f}%"
                    ]
                })
                st.dataframe(stats_df, use_container_width=True)
            
            with col2:
                # æ˜¾ç¤ºé¥¼å›¾
                fig, ax = plt.subplots(figsize=(8, 6))
                labels = ['é€šè¿‡', 'æœªé€šè¿‡']
                sizes = [results['pass_count'], results['count'] - results['pass_count']]
                colors = ['#4CAF50', '#FF5252']
                
                ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
                ax.axis('equal')
                ax.set_title('è´¨é‡è¯„ä¼°é€šè¿‡ç‡')
                
                st.pyplot(fig)
                plt.close(fig)
            
            # æ˜¾ç¤ºç›´æ–¹å›¾
            st.write("**è´¨é‡åˆ†æ•°åˆ†å¸ƒ:**")
            df = st.session_state.workflow_results.to_pandas()
            scores = df["text_quality_score"]
            
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.hist(scores, bins=20, alpha=0.7, color='#2196F3')
            ax.axvline(0.5, color='red', linestyle='--', label='é˜ˆå€¼')
            ax.set_xlabel('è´¨é‡åˆ†æ•°')
            ax.set_ylabel('é¢‘æ•°')
            ax.set_title('è´¨é‡åˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾')
            ax.legend()
            
            st.pyplot(fig)
            plt.close(fig)
    
    def _display_text_length_chart(self, results: Dict[str, Any]):
        """æ˜¾ç¤ºæ–‡æœ¬é•¿åº¦å›¾è¡¨"""
        with st.expander("æ–‡æœ¬é•¿åº¦åˆ†æ", expanded=True):
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write("**ç»Ÿè®¡ä¿¡æ¯:**")
                stats_df = pd.DataFrame({
                    "æŒ‡æ ‡": ["å¹³å‡é•¿åº¦", "ä¸­ä½æ•°", "æ ‡å‡†å·®", "æœ€å°å€¼", "æœ€å¤§å€¼"],
                    "å€¼": [
                        f"{results['mean']:.2f}",
                        f"{results['median']:.2f}",
                        f"{results['std']:.2f}",
                        results['min'],
                        results['max']
                    ]
                })
                st.dataframe(stats_df, use_container_width=True)
            
            with col2:
                # æ˜¾ç¤ºç®±çº¿å›¾
                df = st.session_state.workflow_results.to_pandas()
                lengths = df["text_length"]
                
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.boxplot(lengths)
                ax.set_ylabel('æ–‡æœ¬é•¿åº¦')
                ax.set_title('æ–‡æœ¬é•¿åº¦åˆ†å¸ƒç®±çº¿å›¾')
                
                st.pyplot(fig)
                plt.close(fig)
            
            # æ˜¾ç¤ºç›´æ–¹å›¾
            st.write("**æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ:**")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.hist(lengths, bins=30, alpha=0.7, color='#9C27B0')
            ax.set_xlabel('æ–‡æœ¬é•¿åº¦')
            ax.set_ylabel('é¢‘æ•°')
            ax.set_title('æ–‡æœ¬é•¿åº¦åˆ†å¸ƒç›´æ–¹å›¾')
            
            st.pyplot(fig)
            plt.close(fig)
    
    def _add_log(self, action: str, message: str, level: str = "INFO"):
        """æ·»åŠ æ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "action": action,
            "message": message,
            "level": level
        }
        
        st.session_state.processing_logs.append(log_entry)
    
    def _get_download_link(self, df: daft.DataFrame, filename: str, text: str):
        """è·å–ä¸‹è½½é“¾æ¥"""
        # è½¬æ¢ä¸ºpandas DataFrame
        pd_df = df.to_pandas()
        
        # åˆ›å»ºCSV
        csv = pd_df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
        return href