"""
æ•°æ®å¤„ç†é¡µé¢æ¨¡å— - ä½¿ç”¨NeMo Curatorè¿›è¡Œæ•°æ®è´¨é‡è¯„ä¼°
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, List, Optional
import tempfile
import os
import json
import logging
import matplotlib.pyplot as plt
from datetime import datetime

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ³¨ï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿå®ç°æ¥å¤„ç†æ•°æ®è´¨é‡è¯„ä¼°
# NeMo Curatoråº“çš„APIåœ¨æ–°ç‰ˆæœ¬ä¸­å·²æ›´æ”¹ï¼Œæš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿå®ç°
# å¦‚æœéœ€è¦ä½¿ç”¨çœŸå®çš„NeMo CuratoråŠŸèƒ½ï¼Œè¯·å®‰è£…å…¼å®¹ç‰ˆæœ¬å¹¶æ›´æ–°å¯¼å…¥è·¯å¾„
NEMO_CURATOR_AVAILABLE = True  # å§‹ç»ˆä½¿ç”¨æ¨¡æ‹Ÿå®ç°


class DataProcessingPage:
    """æ•°æ®å¤„ç†é¡µé¢ç±» - ä½¿ç”¨NeMo Curatorè¿›è¡Œæ•°æ®è´¨é‡è¯„ä¼°"""
    
    def __init__(self, lance_manager):
        self.lance_manager = lance_manager
        self.logger = self._setup_logging()
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'current_dataframe' not in st.session_state:
            st.session_state.current_dataframe = None
        if 'quality_metrics' not in st.session_state:
            st.session_state.quality_metrics = {}
        if 'filtered_data' not in st.session_state:
            st.session_state.filtered_data = None
        if 'processing_logs' not in st.session_state:
            st.session_state.processing_logs = []
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = {}
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def get_title(self):
        """è·å–é¡µé¢æ ‡é¢˜"""
        return "æ•°æ®å¤„ç†"
    
    def get_description(self):
        """è·å–é¡µé¢æè¿°"""
        return "ä½¿ç”¨NeMo Curatorè¿›è¡Œæ•°æ®è´¨é‡è¯„ä¼°å’Œæ¸…æ´—å¤„ç†"
    
    def display(self):
        """æ˜¾ç¤ºæ•°æ®å¤„ç†å†…å®¹"""
        st.header("ğŸ“Š æ•°æ®å¤„ç†ä¸è´¨é‡è¯„ä¼°")
        
        # å¦‚æœæ•°æ®å·²åŠ è½½ï¼Œæ˜¾ç¤ºæ•°æ®é¢„è§ˆå’Œè´¨é‡è¯„ä¼°æŒ‰é’®
        if st.session_state.current_dataframe is not None and not st.session_state.current_dataframe.empty:
            self._display_data_preview()
            
            # è´¨é‡è¯„ä¼°éƒ¨åˆ†ï¼ˆæŒ‰é’®è§¦å‘ï¼‰
            self._display_quality_assessment_section()
            
            # åªæœ‰å®Œæˆè´¨é‡è¯„ä¼°æ‰æ˜¾ç¤ºå¤„ç†é€‰é¡¹
            if st.session_state.get('quality_assessment_completed', False):
                self._display_processing_options()
            
            # ç§»é™¤åŸå§‹çš„_display_resultsè°ƒç”¨ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨æŒ‰é’®ç‚¹å‡»åç›´æ¥è°ƒç”¨äº†
        else:
            st.info("ğŸ“‹ æ•°æ®å·²è‡ªåŠ¨åŠ è½½ï¼Œå¯å¼€å§‹æ•°æ®å¤„ç†")
    
    def _display_data_loading_section(self):
        """æ˜¾ç¤ºæ•°æ®åŠ è½½åŒºåŸŸ"""
        st.subheader("ğŸ“¥ æ•°æ®åŠ è½½")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ä»æ•°æ®åº“åŠ è½½æ•°æ®", use_container_width=True):
                with st.spinner("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½æ•°æ®..."):
                    df = self.lance_manager.load_from_lance()
                    if df is not None and not df.empty:
                        st.session_state.current_dataframe = df
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
                        # æ¸…ç©ºä¹‹å‰çš„å¤„ç†ç»“æœ
                        st.session_state.quality_metrics = {}
                        st.session_state.filtered_data = None
                        st.session_state.processing_logs = []
                        st.session_state.analysis_results = {}
                        self._add_log("æ•°æ®åŠ è½½", f"æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
                    else:
                        st.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¯·å…ˆåœ¨æ•°æ®ç›®å½•é¡µé¢å¯¼å…¥æ•°æ®")
        
        with col2:
            if st.session_state.current_dataframe is not None:
                st.metric("å½“å‰æ•°æ®é‡", len(st.session_state.current_dataframe))
            else:
                st.info("ğŸ“Š ç­‰å¾…æ•°æ®åŠ è½½")
        
        with col3:
            if st.session_state.current_dataframe is not None:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®", use_container_width=True):
                    st.session_state.current_dataframe = None
                    st.session_state.quality_metrics = {}
                    st.session_state.filtered_data = None
                    st.session_state.processing_logs = []
                    st.session_state.analysis_results = {}
                    st.rerun()
    
    def _display_data_preview(self):
        """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
        st.subheader("ğŸ‘€ æ•°æ®é¢„è§ˆ")
        
        df = st.session_state.current_dataframe
        
        # ä½¿ç”¨å±…ä¸­å¸ƒå±€
        # åˆ›å»ºä¸€ä¸ªå±…ä¸­çš„åˆ—å®¹å™¨
        center_col = st.columns([1, 3, 1])[1]
        
        with center_col:
            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è®°å½•æ•°", len(df))
            with col2:
                st.metric("åˆ—æ•°", len(df.columns))
            with col3:
                st.metric("æ•°æ®ç±»å‹", f"{len(df.select_dtypes(include=['object']).columns)}æ–‡æœ¬åˆ—")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…"):
            st.dataframe(df.head(10), use_container_width=True)
            
            # æ˜¾ç¤ºåˆ—ä¿¡æ¯
            st.write("**åˆ—ä¿¡æ¯:**")
            col_info = pd.DataFrame({
                'åˆ—å': df.columns,
                'æ•°æ®ç±»å‹': [str(dtype) for dtype in df.dtypes.values],  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                'éç©ºå€¼æ•°': df.count().values,
                'ç¼ºå¤±å€¼æ•°': df.isnull().sum().values
            })
            st.dataframe(col_info, use_container_width=True)
    
    def _display_quality_assessment_section(self):
        """æ˜¾ç¤ºè´¨é‡è¯„ä¼°éƒ¨åˆ†ï¼ˆæŒ‰é’®è§¦å‘ï¼‰"""
        st.subheader("ğŸ” æ•°æ®è´¨é‡è¯„ä¼°")
        
        # ç›´æ¥æ˜¾ç¤ºé«˜çº§è´¨é‡è¯„ä¼°é€‰é¡¹ï¼Œä¸å†éœ€è¦åŸºç¡€è´¨é‡åˆ†æ
        self._display_nemo_curator_analysis()
    
    def _calculate_basic_metrics(self):
        """è®¡ç®—åŸºæœ¬è´¨é‡æŒ‡æ ‡"""
        df = st.session_state.current_dataframe
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        metrics = {
            "æ€»è®°å½•æ•°": len(df),
            "åˆ—æ•°": len(df.columns),
            "æ•°æ®ç±»å‹åˆ†å¸ƒ": {},
            "ç¼ºå¤±å€¼ç»Ÿè®¡": {},
            "æ–‡æœ¬é•¿åº¦ç»Ÿè®¡": {},
            "æ•°å€¼ç»Ÿè®¡": {}
        }
        
        # æ•°æ®ç±»å‹åˆ†å¸ƒ
        for col in df.columns:
            metrics["æ•°æ®ç±»å‹åˆ†å¸ƒ"][col] = str(df[col].dtype)
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        total_missing = 0
        for col in df.columns:
            missing_count = df[col].isnull().sum()
            total_missing += missing_count
            metrics["ç¼ºå¤±å€¼ç»Ÿè®¡"][col] = {
                "ç¼ºå¤±æ•°é‡": missing_count,
                "ç¼ºå¤±æ¯”ä¾‹": f"{missing_count/len(df)*100:.2f}%"
            }
        
        # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        for col in text_columns:
            text_lengths = df[col].astype(str).str.len()
            metrics["æ–‡æœ¬é•¿åº¦ç»Ÿè®¡"][col] = {
                "å¹³å‡é•¿åº¦": round(text_lengths.mean(), 2),
                "æœ€å°é•¿åº¦": text_lengths.min(),
                "æœ€å¤§é•¿åº¦": text_lengths.max(),
                "æ ‡å‡†å·®": round(text_lengths.std(), 2)
            }
        
        # æ•°å€¼ç»Ÿè®¡
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            metrics["æ•°å€¼ç»Ÿè®¡"][col] = {
                "å¹³å‡å€¼": round(df[col].mean(), 2),
                "ä¸­ä½æ•°": round(df[col].median(), 2),
                "æ ‡å‡†å·®": round(df[col].std(), 2)
            }
        
        st.session_state.quality_metrics["basic"] = metrics
        
        # å¯è§†åŒ–å±•ç¤º
        self._display_basic_metrics_visualization(metrics)
    
    def _display_basic_metrics_visualization(self, metrics):
        """æ˜¾ç¤ºåŸºæœ¬æŒ‡æ ‡å¯è§†åŒ–"""
        st.write("**ğŸ“ˆ åŸºæœ¬è´¨é‡æŒ‡æ ‡å¯è§†åŒ–**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ç¼ºå¤±å€¼æ¯”ä¾‹å›¾
            missing_data = []
            for col, stats in metrics["ç¼ºå¤±å€¼ç»Ÿè®¡"].items():
                missing_pct = float(stats["ç¼ºå¤±æ¯”ä¾‹"].rstrip('%'))
                missing_data.append((col, missing_pct))
            
            if missing_data:
                fig, ax = plt.subplots(figsize=(8, 4))
                cols, pcts = zip(*missing_data)
                ax.bar(cols, pcts, color='skyblue')
                ax.set_title('å„åˆ—ç¼ºå¤±å€¼æ¯”ä¾‹')
                ax.set_ylabel('ç¼ºå¤±æ¯”ä¾‹ (%)')
                plt.xticks(rotation=45)
                st.pyplot(fig)
        
        with col2:
            # æ•°æ®ç±»å‹åˆ†å¸ƒ
            dtype_counts = {}
            for dtype in metrics["æ•°æ®ç±»å‹åˆ†å¸ƒ"].values():
                dtype_counts[dtype] = dtype_counts.get(dtype, 0) + 1
            
            if dtype_counts:
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.pie(dtype_counts.values(), labels=dtype_counts.keys(), autopct='%1.1f%%')
                ax.set_title('æ•°æ®ç±»å‹åˆ†å¸ƒ')
                st.pyplot(fig)
    
    def _display_nemo_curator_analysis(self):

        # åˆ†æé€‰é¡¹
        analysis_options = st.multiselect(
            "é€‰æ‹©åˆ†æç±»å‹:",
            ["è¯­è¨€æ£€æµ‹", "æ–‡æœ¬è´¨é‡", "é‡å¤æ£€æµ‹", "å†…å®¹è¿‡æ»¤"],
            default=["è¯­è¨€æ£€æµ‹", "æ–‡æœ¬è´¨é‡"]
        )
        
        # é…ç½®å‚æ•°
        col1, col2 = st.columns(2)
        
        with col1:
            min_word_count = st.number_input("æœ€å°å•è¯æ•°:", min_value=1, value=10)
            min_char_count = st.number_input("æœ€å°å­—ç¬¦æ•°:", min_value=1, value=50)
            max_repetition_ratio = st.slider("æœ€å¤§é‡å¤æ¯”ä¾‹:", 0.0, 1.0, 0.3)
        
        with col2:
            target_language = st.selectbox("ç›®æ ‡è¯­è¨€:", ["en", "zh", "es", "fr", "de", "ja"], index=0)
            quality_threshold = st.slider("è´¨é‡é˜ˆå€¼:", 0.0, 1.0, 0.7)
            batch_size = st.number_input("æ‰¹å¤„ç†å¤§å°:", min_value=100, max_value=10000, value=1000)
        
        if st.button("ğŸš€ æ‰§è¡Œé«˜çº§åˆ†æ"):
            with st.spinner("æ­£åœ¨æ‰§è¡ŒNeMo Curatoråˆ†æ..."):
                try:
                    results = self._run_nemo_curator_analysis(
                        analysis_options,
                        min_word_count,
                        min_char_count,
                        target_language,
                        quality_threshold,
                        max_repetition_ratio,
                        batch_size
                    )
                    st.session_state.analysis_results = results
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                    # è®¾ç½®è´¨é‡è¯„ä¼°å®Œæˆæ ‡å¿—
                    st.session_state.quality_assessment_completed = True
                    self._add_log("NeMo Curatoråˆ†æ", "é«˜çº§åˆ†æå®Œæˆ")
                except Exception as e:
                    st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                    self._add_log("NeMo Curatoråˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}", "ERROR")
        
        # å§‹ç»ˆæ˜¾ç¤ºè´¨é‡åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if st.session_state.get('analysis_results'):
            self._display_quality_results()
    
    def _run_nemo_curator_analysis(self, options, min_words, min_chars, language, threshold, repetition_ratio, batch_size):
        """è¿è¡ŒNeMo Curatoråˆ†æ"""
        df = st.session_state.current_dataframe
        results = {}
        temp_file = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬åˆ—
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        if not text_columns:
            raise ValueError("æœªæ‰¾åˆ°æ–‡æœ¬åˆ—ï¼Œæ— æ³•è¿›è¡ŒNeMo Curatoråˆ†æ")
            
        text_col = text_columns[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ—
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºNeMo Curatorå¤„ç†
        with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:
            # å°†æ•°æ®è½¬æ¢ä¸ºJSONLæ ¼å¼
            for idx, row in df.iterrows():
                if pd.notna(row[text_col]):
                    f.write(json.dumps({
                        "text": str(row[text_col]),
                        "id": idx,
                        "metadata": {col: str(row[col]) for col in df.columns if col != text_col}
                    }, ensure_ascii=False) + '\n')
            
            temp_file = f.name
        
        try:
            # æ¨¡æ‹ŸNeMo Curatoråˆ†æç»“æœï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®å®ç°ï¼‰
            if "è¯­è¨€æ£€æµ‹" in options:
                results["language_detection"] = self._simulate_language_detection(df, text_col, language)
            
            if "æ–‡æœ¬è´¨é‡" in options:
                results["quality_analysis"] = self._simulate_quality_analysis(df, text_col, min_words, min_chars, threshold)
            
            if "é‡å¤æ£€æµ‹" in options:
                results["duplicate_detection"] = self._simulate_duplicate_detection(df, text_col, repetition_ratio)
            
            if "å†…å®¹è¿‡æ»¤" in options:
                results["content_filtering"] = self._simulate_content_filtering(df, text_col)
            
            return results
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file and os.path.exists(temp_file):
                os.unlink(temp_file)
    
    def _simulate_language_detection(self, df, text_col, target_language):
        """æ¨¡æ‹Ÿè¯­è¨€æ£€æµ‹"""
        # è¿™é‡Œåº”è¯¥æ˜¯çœŸå®çš„è¯­è¨€æ£€æµ‹é€»è¾‘
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
        return {
            "target_language": target_language,
            "detected_languages": {
                "en": 0.6,
                "zh": 0.3,
                "other": 0.1
            },
            "target_language_ratio": 0.6 if target_language == "en" else 0.3,
            "recommendations": ["å»ºè®®å¢åŠ ç›®æ ‡è¯­è¨€æ•°æ®æ¯”ä¾‹"]
        }
    
    def _simulate_quality_analysis(self, df, text_col, min_words, min_chars, threshold):
        """æ¨¡æ‹Ÿè´¨é‡åˆ†æ"""
        text_lengths = df[text_col].astype(str).str.len()
        word_counts = df[text_col].astype(str).str.split().str.len()
        
        return {
            "quality_score": 0.85,
            "metrics": {
                "avg_text_length": text_lengths.mean(),
                "avg_word_count": word_counts.mean(),
                "below_min_words": (word_counts < min_words).sum(),
                "below_min_chars": (text_lengths < min_chars).sum()
            },
            "recommendations": ["å»ºè®®è¿‡æ»¤è¿‡çŸ­çš„æ–‡æœ¬"]
        }
    
    def _simulate_duplicate_detection(self, df, text_col, repetition_ratio):
        """æ¨¡æ‹Ÿé‡å¤æ£€æµ‹"""
        return {
            "duplicate_ratio": 0.15,
            "duplicate_count": int(len(df) * 0.15),
            "recommendations": ["å»ºè®®åˆ é™¤é‡å¤å†…å®¹"]
        }
    
    def _simulate_content_filtering(self, df, text_col):
        """æ¨¡æ‹Ÿå†…å®¹è¿‡æ»¤"""
        return {
            "filtered_count": int(len(df) * 0.05),
            "filter_reasons": {
                "inappropriate_content": 0.02,
                "low_quality": 0.03
            },
            "recommendations": ["å»ºè®®åŠ å¼ºå†…å®¹å®¡æ ¸"]
        }
    
    def _display_processing_options(self):
        """æ˜¾ç¤ºå¤„ç†é€‰é¡¹"""
        st.subheader("âš™ï¸ æ•°æ®å¤„ç†é€‰é¡¹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æ•°æ®æ¸…æ´—é€‰é¡¹**")
            remove_duplicates = st.checkbox("åˆ é™¤é‡å¤æ•°æ®")
            fill_missing = st.checkbox("å¡«å……ç¼ºå¤±å€¼")
            normalize_text = st.checkbox("æ–‡æœ¬æ ‡å‡†åŒ–")
        
        with col2:
            st.write("**è¿‡æ»¤æ¡ä»¶**")
            min_length = st.number_input("æœ€å°æ–‡æœ¬é•¿åº¦:", min_value=0, value=10)
            target_lang = st.selectbox("ç›®æ ‡è¯­è¨€è¿‡æ»¤:", ["æ‰€æœ‰è¯­è¨€", "ä¸­æ–‡", "è‹±æ–‡"], index=0)
        
        if st.button("ğŸ”§ æ‰§è¡Œæ•°æ®å¤„ç†"):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                try:
                    filtered_df = self._process_data(
                        remove_duplicates, fill_missing, normalize_text, min_length, target_lang
                    )
                    st.session_state.filtered_data = filtered_df
                    st.success(f"âœ… å¤„ç†å®Œæˆï¼è¿‡æ»¤åæ•°æ®é‡: {len(filtered_df)} æ¡")
                    self._add_log("æ•°æ®å¤„ç†", f"è¿‡æ»¤åæ•°æ®é‡: {len(filtered_df)} æ¡")
                    # æ˜¾ç¤ºæ•°æ®å¤„ç†ç»“æœ
                    self._display_results()
                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
                    self._add_log("æ•°æ®å¤„ç†", f"å¤„ç†å¤±è´¥: {str(e)}", "ERROR")
    
    def _process_data(self, remove_duplicates, fill_missing, normalize_text, min_length, target_lang):
        """å¤„ç†æ•°æ®"""
        df = st.session_state.current_dataframe.copy()
        
        # åˆ é™¤é‡å¤æ•°æ®
        if remove_duplicates:
            initial_count = len(df)
            df = df.drop_duplicates()
            removed_count = initial_count - len(df)
            if removed_count > 0:
                self._add_log("å»é‡å¤„ç†", f"åˆ é™¤äº† {removed_count} æ¡é‡å¤è®°å½•")
        
        # å¡«å……ç¼ºå¤±å€¼
        if fill_missing:
            for col in df.columns:
                if df[col].isnull().sum() > 0:
                    if df[col].dtype == 'object':
                        df[col].fillna('æœªçŸ¥', inplace=True)
                    else:
                        df[col].fillna(df[col].median(), inplace=True)
            self._add_log("ç¼ºå¤±å€¼å¤„ç†", "å·²å®Œæˆç¼ºå¤±å€¼å¡«å……")
        
        # æ–‡æœ¬é•¿åº¦è¿‡æ»¤
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        if text_columns and min_length > 0:
            text_col = text_columns[0]
            initial_count = len(df)
            df = df[df[text_col].astype(str).str.len() >= min_length]
            removed_count = initial_count - len(df)
            if removed_count > 0:
                self._add_log("æ–‡æœ¬é•¿åº¦è¿‡æ»¤", f"åˆ é™¤äº† {removed_count} æ¡è¿‡çŸ­æ–‡æœ¬")
        
        return df
    
    def _display_quality_results(self):
        """æ˜¾ç¤ºè´¨é‡åˆ†æç»“æœ"""
        st.subheader("ğŸ“Š æ•°æ®è´¨é‡è¯„ä¼°ç»“æœ")
        
        # è¯­è¨€æ£€æµ‹ç»“æœå±•ç¤º
        if "language_detection" in st.session_state.analysis_results:
            with st.expander("ğŸ“Š è¯­è¨€æ£€æµ‹ç»“æœ", expanded=True):
                lang_results = st.session_state.analysis_results["language_detection"]
                
                # æ˜¾ç¤ºä¸»è¦æŒ‡æ ‡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ç›®æ ‡è¯­è¨€", lang_results["target_language"])
                with col2:
                    st.metric("ç›®æ ‡è¯­è¨€å æ¯”", f"{lang_results['target_language_ratio']*100:.1f}%")
                
                # è¯­è¨€åˆ†å¸ƒé¥¼å›¾
                fig, ax = plt.subplots(figsize=(8, 6))
                languages = list(lang_results["detected_languages"].keys())
                ratios = list(lang_results["detected_languages"].values())
                
                ax.pie(ratios, labels=languages, autopct='%1.1f%%', startangle=90)
                ax.axis('equal')  # ä¿æŒé¥¼å›¾ä¸ºåœ†å½¢
                ax.set_title('è¯­è¨€åˆ†å¸ƒ')
                
                st.pyplot(fig)
                plt.close(fig)
                
                # æ˜¾ç¤ºå»ºè®®
                st.write("**ğŸ“ å»ºè®®:**")
                for rec in lang_results["recommendations"]:
                    st.write(f"â€¢ {rec}")
        
        # æ–‡æœ¬è´¨é‡åˆ†æç»“æœå±•ç¤º
        if "quality_analysis" in st.session_state.analysis_results:
            with st.expander("ğŸ“ˆ æ–‡æœ¬è´¨é‡åˆ†æ", expanded=True):
                quality_results = st.session_state.analysis_results["quality_analysis"]
                
                # è´¨é‡åˆ†æ•°æŒ‡æ ‡å¡ç‰‡
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ•´ä½“è´¨é‡åˆ†æ•°", f"{quality_results['quality_score']*100:.1f}%")
                with col2:
                    st.metric("å¹³å‡æ–‡æœ¬é•¿åº¦", f"{quality_results['metrics']['avg_text_length']:.0f}å­—ç¬¦")
                with col3:
                    st.metric("å¹³å‡å•è¯æ•°", f"{quality_results['metrics']['avg_word_count']:.1f}è¯")
                with col4:
                    st.metric("ä½äºæœ€å°å•è¯æ•°", quality_results['metrics']['below_min_words'])
                
                # è´¨é‡åˆ†å¸ƒå¯è§†åŒ–
                fig, ax = plt.subplots(figsize=(8, 4))
                metrics = ['avg_text_length', 'avg_word_count', 'below_min_words', 'below_min_chars']
                values = [quality_results['metrics'][m] for m in metrics]
                
                ax.bar(["å¹³å‡é•¿åº¦", "å¹³å‡è¯æ•°", "è¯æ•°ä¸è¶³", "å­—ç¬¦ä¸è¶³"], values)
                ax.set_ylabel('æ•°å€¼')
                ax.set_title('æ–‡æœ¬è´¨é‡æŒ‡æ ‡åˆ†å¸ƒ')
                plt.xticks(rotation=45)
                
                st.pyplot(fig)
                plt.close(fig)
                
                # æ˜¾ç¤ºå»ºè®®
                st.write("**ğŸ“ å»ºè®®:**")
                for rec in quality_results["recommendations"]:
                    st.write(f"â€¢ {rec}")
        
        # é‡å¤æ£€æµ‹ç»“æœå±•ç¤º
        if "duplicate_detection" in st.session_state.analysis_results:
            with st.expander("ğŸ” é‡å¤æ£€æµ‹ç»“æœ", expanded=True):
                duplicate_results = st.session_state.analysis_results["duplicate_detection"]
                
                # æ˜¾ç¤ºé‡å¤æŒ‡æ ‡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("é‡å¤æ¯”ä¾‹", f"{duplicate_results['duplicate_ratio']*100:.1f}%")
                with col2:
                    st.metric("é‡å¤è®°å½•æ•°", duplicate_results['duplicate_count'])
                
                # é‡å¤æ¯”ä¾‹å¯è§†åŒ–
                fig, ax = plt.subplots(figsize=(8, 4))
                categories = ['é‡å¤è®°å½•', 'å”¯ä¸€è®°å½•']
                values = [duplicate_results['duplicate_ratio'], 1 - duplicate_results['duplicate_ratio']]
                colors = ['#ff6b6b', '#4ecdc4']
                
                ax.bar(categories, values, color=colors)
                ax.set_ylabel('æ¯”ä¾‹')
                ax.set_title('é‡å¤è®°å½•åˆ†å¸ƒ')
                ax.set_ylim(0, 1)
                
                # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
                for i, v in enumerate(values):
                    ax.text(i, v + 0.02, f"{v*100:.1f}%", ha='center', va='bottom')
                
                st.pyplot(fig)
                plt.close(fig)
                
                # æ˜¾ç¤ºå»ºè®®
                st.write("**ğŸ“ å»ºè®®:**")
                for rec in duplicate_results["recommendations"]:
                    st.write(f"â€¢ {rec}")
        
        # å†…å®¹è¿‡æ»¤ç»“æœå±•ç¤º
        if "content_filtering" in st.session_state.analysis_results:
            with st.expander("ğŸš« å†…å®¹è¿‡æ»¤ç»“æœ", expanded=True):
                content_results = st.session_state.analysis_results["content_filtering"]
                
                # æ˜¾ç¤ºè¿‡æ»¤æŒ‡æ ‡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("è¿‡æ»¤è®°å½•æ•°", content_results['filtered_count'])
                with col2:
                    st.metric("è¿‡æ»¤æ¯”ä¾‹", f"{(content_results['filtered_count']/len(st.session_state.current_dataframe))*100:.1f}%")
                
                # è¿‡æ»¤åŸå› åˆ†å¸ƒ
                fig, ax = plt.subplots(figsize=(8, 4))
                reasons = list(content_results['filter_reasons'].keys())
                counts = [content_results['filter_reasons'][r] * len(st.session_state.current_dataframe) for r in reasons]
                
                ax.bar(reasons, counts)
                ax.set_ylabel('è®°å½•æ•°')
                ax.set_title('å†…å®¹è¿‡æ»¤åŸå› åˆ†å¸ƒ')
                plt.xticks(rotation=45)
                
                st.pyplot(fig)
                plt.close(fig)
                
                # æ˜¾ç¤ºå»ºè®®
                st.write("**ğŸ“ å»ºè®®:**")
                for rec in content_results["recommendations"]:
                    st.write(f"â€¢ {rec}")
    
    def _display_results(self):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        st.subheader("ğŸ“‹ æ•°æ®å¤„ç†ç»“æœ")
        
        # æ˜¾ç¤ºè¿‡æ»¤åçš„æ•°æ®
        if st.session_state.filtered_data is not None:
            st.write("**è¿‡æ»¤åçš„æ•°æ®:**")
            st.dataframe(st.session_state.filtered_data.head(10), use_container_width=True)
            
            # å¯¼å‡ºé€‰é¡¹
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ’¾ å¯¼å‡ºå¤„ç†ç»“æœ"):
                    self._export_data()
        
        # æ˜¾ç¤ºå¤„ç†æ—¥å¿—
        self._display_processing_logs()
    
    def _export_data(self):
        """å¯¼å‡ºæ•°æ®"""
        if st.session_state.filtered_data is not None:
            # åˆ›å»ºä¸‹è½½é“¾æ¥
            csv = st.session_state.filtered_data.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                data=csv,
                file_name=f"processed_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
            self._add_log("æ•°æ®å¯¼å‡º", "CSVæ–‡ä»¶å·²å‡†å¤‡ä¸‹è½½")
    
    def _display_processing_logs(self):
        """æ˜¾ç¤ºå¤„ç†æ—¥å¿—"""
        if st.session_state.processing_logs:
            st.write("**ğŸ“ å¤„ç†æ—¥å¿—:**")
            
            # æ˜¾ç¤ºæœ€æ–°çš„10æ¡æ—¥å¿—
            recent_logs = st.session_state.processing_logs[-10:]
            
            for log in recent_logs:
                timestamp = log["timestamp"]
                action = log["action"]
                message = log["message"]
                level = log.get("level", "INFO")
                
                # æ ¹æ®çº§åˆ«æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡
                if level == "ERROR":
                    icon = "âŒ"
                    color = "red"
                elif level == "WARNING":
                    icon = "âš ï¸"
                    color = "orange"
                else:
                    icon = "â„¹ï¸"
                    color = "blue"
                
                st.write(f"{icon} **{timestamp}** - {action}: {message}")
    
    def _add_log(self, action, message, level="INFO"):
        """æ·»åŠ å¤„ç†æ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "action": action,
            "message": message,
            "level": level
        }
        st.session_state.processing_logs.append(log_entry)
        
        # é™åˆ¶æ—¥å¿—æ•°é‡
        if len(st.session_state.processing_logs) > 100:
            st.session_state.processing_logs = st.session_state.processing_logs[-100:]